{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# 加载任务1处理过的数据集\n",
    "pickle_file = 'E:/Python/data/notMNIST.pickle'\n",
    "with open(pickle_file, 'rb') as f:  \n",
    "    save = pickle.load(f)\n",
    "    train_dataset = save['train_dataset']\n",
    "    train_labels = save['train_labels']\n",
    "    valid_dataset = save['valid_dataset']\n",
    "    valid_labels = save['valid_labels']\n",
    "    test_dataset = save['test_dataset']\n",
    "    test_labels = save['test_labels']\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Training set', train_dataset.shape, train_labels.shape)\n",
    "    print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "    print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 784) (200000, 10)\n",
      "Validation set (10000, 784) (10000, 10)\n",
      "Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    # reshape(-1, image_size * image_size)代表你只知道数组的第二个维度，\n",
    "    # 剩下的维度由Numpy自动计算得出，比如原本维度（20000*28*28）train_dataset\n",
    "    # reshape过后的维度就是20000*(28*28)\n",
    "    # test_dataset的维度就是10000*(28*28)\n",
    "    dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "    # 将图片标签映射为数组形式，比如1映射为[False, True, False, ..., False, False, False]\n",
    "    labels = (np.arange(num_labels)) == labels[:, None].astype(np.float32)\n",
    "    return dataset, labels\n",
    "\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.argmax()返回沿着轴线方向最大值的索引值\n",
    "# 判断预测标签与原标签是否相同，并计算相同标签的数目，除以总标签数，即正确率\n",
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  问题1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、Multinomial logistic regression with L2 regularization\n",
    "\n",
    "    \n",
    "给逻辑斯蒂和神经网络模型引入可调节的L2正则化参数。在TensorFlow中，使用nn.l2_loss(t)给张量计算L2损失，合适的正则化系数会给模型的验证集、测试集准确度带来提升。经过引入L2正则化，LR与神经网络模型准确率相比未引入正则化有显著提升。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# With gradient descent training, even this much data is prohibitive.\n",
    "# Subset the training data for faster turnaround.\n",
    "# 先取10000的样本量\n",
    "train_subset = 10000\n",
    "beta = 0.01\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Input data.（输入）\n",
    "    # Load the training, validation and test data into constants that are\n",
    "    # attached to the graph.\n",
    "    tf_train_dataset = tf.constant(train_dataset[:train_subset, :])\n",
    "    tf_train_labels = tf.constant(train_labels[:train_subset])\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "    # Variables.（变量）\n",
    "    # These are the parameters that we are going to be training. The weight\n",
    "    # matrix will be initialized using random valued following a (truncated)\n",
    "    # normal distribution. The biases get initialized to zero.\n",
    "    # 随机初始化权重矩阵（服从正态分布），偏置项初始化为0\n",
    "    weights = tf.Variable(tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "    biases = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "    # Training computation.\n",
    "    # We multiply the inputs with the weight matrix, and add biases. We compute\n",
    "    # the softmax and cross-entropy (it's one operation in TensorFlow, because\n",
    "    # it's very common, and it can be optimized). We take the average of this\n",
    "    # cross-entropy across all training examples: that's our loss.\n",
    "    logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "    # 注意正确的方式应为tf.nn.softmax_cross_entropy_with_logits(logits=..., labels=...)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n",
    "    # 添加L2正则化项\n",
    "    regularization = tf.nn.l2_loss(weights)\n",
    "    loss = tf.reduce_mean(loss + regularization * beta)\n",
    "\n",
    "    # Optimizer.\n",
    "    # We are going to find the minimum of this loss using gradient descent.\n",
    "    # 梯度下降算法优化：tf.train.GradientDescentOptimizer()，找到最小损失\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "    # Predictions for the training, validation, and test data.\n",
    "    # These are not part of training, but merely here so that we can report\n",
    "    # accuracy figures as we train.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "    test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-21e8af513b94>:8: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "初始化变量...\n",
      "迭代次数到 0 时损失为: 47.846046\n",
      "Wall time: 0 ns\n",
      "训练集准确率: 10.8%\n",
      "Wall time: 533 µs\n",
      "验证集准确率: 13.3%\n",
      "Wall time: 87.2 ms\n",
      "迭代次数到 100 时损失为: 11.855865\n",
      "Wall time: 0 ns\n",
      "训练集准确率: 73.4%\n",
      "Wall time: 501 µs\n",
      "验证集准确率: 71.7%\n",
      "Wall time: 2.01 ms\n",
      "迭代次数到 200 时损失为: 4.484870\n",
      "Wall time: 0 ns\n",
      "训练集准确率: 78.1%\n",
      "Wall time: 501 µs\n",
      "验证集准确率: 76.2%\n",
      "Wall time: 2.51 ms\n",
      "迭代次数到 300 时损失为: 1.987108\n",
      "Wall time: 502 µs\n",
      "训练集准确率: 81.6%\n",
      "Wall time: 1 ms\n",
      "验证集准确率: 79.5%\n",
      "Wall time: 2.01 ms\n",
      "迭代次数到 400 时损失为: 1.140227\n",
      "Wall time: 0 ns\n",
      "训练集准确率: 83.6%\n",
      "Wall time: 501 µs\n",
      "验证集准确率: 80.9%\n",
      "Wall time: 2.01 ms\n",
      "迭代次数到 500 时损失为: 0.849337\n",
      "Wall time: 0 ns\n",
      "训练集准确率: 83.9%\n",
      "Wall time: 1 ms\n",
      "验证集准确率: 81.6%\n",
      "Wall time: 2.01 ms\n",
      "迭代次数到 600 时损失为: 0.748160\n",
      "Wall time: 0 ns\n",
      "训练集准确率: 84.2%\n",
      "Wall time: 501 µs\n",
      "验证集准确率: 81.7%\n",
      "Wall time: 1.5 ms\n",
      "迭代次数到 700 时损失为: 0.712636\n",
      "Wall time: 501 µs\n",
      "训练集准确率: 84.2%\n",
      "Wall time: 501 µs\n",
      "验证集准确率: 81.8%\n",
      "Wall time: 2.01 ms\n",
      "迭代次数到 800 时损失为: 0.700070\n",
      "Wall time: 0 ns\n",
      "训练集准确率: 84.2%\n",
      "Wall time: 501 µs\n",
      "验证集准确率: 81.8%\n",
      "Wall time: 2.01 ms\n",
      "测试集准确率: 89.3%\n",
      "Wall time: 87.2 ms\n"
     ]
    }
   ],
   "source": [
    "num_steps = 801\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    # This is a one-time operation which ensures the parameters get initialized as\n",
    "    # we described in the graph: random weights for the matrix, zeros for the\n",
    "    # biases. \n",
    "    # 根据上面的做法初始化所有变量\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('初始化变量...')\n",
    "    for step in range(num_steps):\n",
    "    # Run the computations. We tell .run() that we want to run the optimizer,\n",
    "    # and get the loss value and the training predictions returned as numpy\n",
    "    # arrays.\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "        if (step % 100 == 0):\n",
    "            %time print('迭代次数到 %d 时损失为: %f' % (step, l))\n",
    "            %time print('训练集准确率: %.1f%%' % accuracy(predictions, train_labels[:train_subset, :]))\n",
    "    # Calling .eval() on valid_prediction is basically like calling run(), but\n",
    "    # just to get that one numpy array. Note that it recomputes all its graph\n",
    "    # dependencies.\n",
    "            %time print('验证集准确率: %.1f%%' % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    %time print('测试集准确率: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、ReLUs networks with L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "relu_count = 1024 #隐藏节点个数\n",
    "beta = 0.01\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # 输入数据\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    # 变量\n",
    "    # note：这里考到了神经网络中练习参数（权重和偏置项）个数的计算\n",
    "    # see：https://classroom.udacity.com/courses/ud730/lessons/6379031992/concepts/63789029420923\n",
    "    # 输入层→隐藏层：权重个数1024*1*1*(28*28)，偏置项个数1024\n",
    "    # 隐藏层→输出层：权重个数10*1*1*1024，偏置项个数10\n",
    "    # 输出层：10*1\n",
    "    weights = [tf.Variable(tf.truncated_normal([image_size * image_size, relu_count])),\n",
    "              tf.Variable(tf.truncated_normal([relu_count, num_labels]))]\n",
    "    biases = [tf.Variable(tf.zeros([relu_count])),\n",
    "              tf.Variable(tf.zeros([num_labels]))]\n",
    "    \n",
    "    # 训练计算\n",
    "    hidden_layer = tf.nn.relu(tf.add(tf.matmul(tf_train_dataset, weights[0]), biases[0]))\n",
    "    logits = tf.add(tf.matmul(hidden_layer, weights[1]), biases[1])\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n",
    "    regularization_0 = tf.nn.l2_loss(weights[0])\n",
    "    regularization_1 = tf.nn.l2_loss(weights[1])\n",
    "    regularization = regularization_0 + regularization_1\n",
    "    loss = tf.reduce_mean(loss + beta * regularization)\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf_valid_dataset, weights[0]), biases[0]))\n",
    "                                                      , weights[1]), biases[1]))\n",
    "    test_prediction = tf.nn.softmax(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf_test_dataset, weights[0]), biases[0]))\n",
    "                                                      , weights[1]), biases[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-1286133431d5>:4: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "初始化变量...\n",
      "Minibatch loss at step 0: 3564.834961\n",
      "Minibatch 准确率: 4.7%\n",
      "验证集准确率: 23.2%\n",
      "Minibatch loss at step 500: 21.357204\n",
      "Minibatch 准确率: 82.0%\n",
      "验证集准确率: 83.6%\n",
      "Minibatch loss at step 1000: 0.823034\n",
      "Minibatch 准确率: 85.2%\n",
      "验证集准确率: 83.3%\n",
      "Minibatch loss at step 1500: 0.655827\n",
      "Minibatch 准确率: 89.8%\n",
      "验证集准确率: 83.6%\n",
      "Minibatch loss at step 2000: 0.480227\n",
      "Minibatch 准确率: 93.8%\n",
      "验证集准确率: 83.1%\n",
      "Minibatch loss at step 2500: 0.660885\n",
      "Minibatch 准确率: 84.4%\n",
      "验证集准确率: 83.4%\n",
      "Minibatch loss at step 3000: 0.766577\n",
      "Minibatch 准确率: 82.0%\n",
      "验证集准确率: 83.2%\n",
      "测试集准确率: 90.2%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"初始化变量...\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch 准确率: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"验证集准确率: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print(\"测试集准确率: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 问题2\n",
    "\n",
    "考虑数据集很小的极端情形，运行得Minibatch的准确率达到100.0%，发现模型出现过拟合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-3779fbddd8e3>:6: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "初始化变量...\n",
      "Minibatch loss at step 0: 3450.160156\n",
      "Minibatch 准确率: 9.4%\n",
      "验证集准确率: 25.3%\n",
      "Minibatch loss at step 500: 21.149956\n",
      "Minibatch 准确率: 100.0%\n",
      "验证集准确率: 77.4%\n",
      "Minibatch loss at step 1000: 0.486802\n",
      "Minibatch 准确率: 100.0%\n",
      "验证集准确率: 78.7%\n",
      "Minibatch loss at step 1500: 0.312615\n",
      "Minibatch 准确率: 100.0%\n",
      "验证集准确率: 78.9%\n",
      "Minibatch loss at step 2000: 0.296324\n",
      "Minibatch 准确率: 100.0%\n",
      "验证集准确率: 78.9%\n",
      "Minibatch loss at step 2500: 0.284658\n",
      "Minibatch 准确率: 100.0%\n",
      "验证集准确率: 79.0%\n",
      "Minibatch loss at step 3000: 0.283261\n",
      "Minibatch 准确率: 100.0%\n",
      "验证集准确率: 78.9%\n",
      "测试集准确率: 86.0%\n"
     ]
    }
   ],
   "source": [
    "train_dataset_2 = train_dataset[:500, :]\n",
    "train_labels_2 = train_labels[:500]\n",
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"初始化变量...\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels_2.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset_2[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels_2[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch 准确率: %.1f%%\" % (accuracy(predictions, batch_labels)))\n",
    "            print(\"验证集准确率: %.1f%%\" % (accuracy(valid_prediction.eval(), valid_labels)))\n",
    "    print(\"测试集准确率: %.1f%%\" % (accuracy(test_prediction.eval(), test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题3\n",
    "\n",
    "Introduce Dropout on the hidden layer of the neural network. Remember: Dropout should only be introduced during training, not evaluation, otherwise your evaluation results would be stochastic as well. TensorFlow provides nn.dropout() for that, but you have to make sure it's only inserted during training.\n",
    "\n",
    "What happens to our extreme overfitting case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "relu_count = 1024 #隐藏节点个数\n",
    "beta = 0.01\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # 输入数据\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    # 变量\n",
    "    # note：这里考到了神经网络中练习参数（权重和偏置项）个数的计算\n",
    "    # see：https://classroom.udacity.com/courses/ud730/lessons/6379031992/concepts/63789029420923\n",
    "    # 输入层→隐藏层：权重个数1024*1*1*(28*28)，偏置项个数1024\n",
    "    # 隐藏层→输出层：权重个数10*1*1*1024，偏置项个数10\n",
    "    # 输出层：10*1\n",
    "    weights = [tf.Variable(tf.truncated_normal([image_size * image_size, relu_count])),\n",
    "              tf.Variable(tf.truncated_normal([relu_count, num_labels]))]\n",
    "    biases = [tf.Variable(tf.zeros([relu_count])),\n",
    "              tf.Variable(tf.zeros([num_labels]))]\n",
    "    \n",
    "    # 训练计算\n",
    "    # tf.nn.dropout(x, keep_prob,...)，keep_prob参数等于神经元参数保留的比例\n",
    "    keep_prob = 0.9\n",
    "    hidden_layer = tf.nn.relu(tf.add(tf.matmul(tf_train_dataset, weights[0]), biases[0]))\n",
    "    hidden_layer_dropout = tf.nn.dropout(hidden_layer, keep_prob)\n",
    "    logits = tf.add(tf.matmul(hidden_layer_dropout, weights[1]), biases[1])\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n",
    "    regularization_0 = tf.nn.l2_loss(weights[0])\n",
    "    regularization_1 = tf.nn.l2_loss(weights[1])\n",
    "    regularization = regularization_0 + regularization_1\n",
    "    loss = tf.reduce_mean(loss + beta * regularization)\n",
    "    # Optimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    valid_prediction = tf.nn.softmax(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf_valid_dataset, weights[0]), biases[0]))\n",
    "                                                      , weights[1]), biases[1]))\n",
    "    test_prediction = tf.nn.softmax(tf.add(tf.matmul(tf.nn.relu(tf.add(tf.matmul(tf_test_dataset, weights[0]), biases[0]))\n",
    "                                                      , weights[1]), biases[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-1286133431d5>:4: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "初始化变量...\n",
      "Minibatch loss at step 0: 3469.313477\n",
      "Minibatch 准确率: 14.8%\n",
      "验证集准确率: 28.3%\n",
      "Minibatch loss at step 500: 21.401947\n",
      "Minibatch 准确率: 82.8%\n",
      "验证集准确率: 83.6%\n",
      "Minibatch loss at step 1000: 0.841948\n",
      "Minibatch 准确率: 85.2%\n",
      "验证集准确率: 83.2%\n",
      "Minibatch loss at step 1500: 0.665547\n",
      "Minibatch 准确率: 90.6%\n",
      "验证集准确率: 83.6%\n",
      "Minibatch loss at step 2000: 0.493639\n",
      "Minibatch 准确率: 93.0%\n",
      "验证集准确率: 83.0%\n",
      "Minibatch loss at step 2500: 0.664664\n",
      "Minibatch 准确率: 85.2%\n",
      "验证集准确率: 83.4%\n",
      "Minibatch loss at step 3000: 0.781660\n",
      "Minibatch 准确率: 82.0%\n",
      "验证集准确率: 83.4%\n",
      "测试集准确率: 90.3%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"初始化变量...\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"Minibatch 准确率: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "            print(\"验证集准确率: %.1f%%\" % accuracy(valid_prediction.eval(), valid_labels))\n",
    "    print(\"测试集准确率: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题4\n",
    "\n",
    "Try to get the best performance you can using a multi-layer model! The best reported test accuracy using a deep network is 97.1%.\n",
    "\n",
    "One avenue you can explore is to add multiple layers.\n",
    "\n",
    "Another one is to use learning rate decay:\n",
    "```\n",
    "global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "learning_rate = tf.train.exponential_decay(0.5, global_step, ...)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "```\n",
    "\n",
    "既然是深度学习，那么多添加几层神经网络看看效果如何。本实验中我们添加了3个隐藏层，并使用了L2正则化、dropout、learning rate decay等手段防止出现过拟合。\n",
    "\n",
    "经实验发现，决定测试集准确率的参数主要有学习率衰减（learning rate decay）、dropout、迭代次数（num_steps）、隐藏层节点个数，通过调节4组参数，结果显示实验测试集最高的准确率达到96.3%，相比较上一组实验测试集准确率为90.4%有了较大的提升。至于为什么参数这样组合是合理的，笔者暂时也说不上来，不过后续我会继续补充的:D。\n",
    "\n",
    "据说最佳的深度网络正确率达到97.1%。\n",
    "\n",
    "| 参数 |  |  ||\n",
    "| :--- | :----: | :----: | :----: |:----: |\n",
    "| learning rate decay | (100000,0.96) | (100000,0.96) |(1000, 0.7)|(1000, 0.7)|\n",
    "| dropout    |       |    √  ||√|\n",
    "|hidden_layer_nodes|1024,512,256|1024,512,256|4096,2048,128|4096,2048,128|\n",
    "|num_steps|20001|20001|12001|12001|\n",
    "|test accuracy|94.1|95.2|96.3|95.6|\n",
    "\n",
    "遗留的问题：\n",
    "\n",
    "- 权重初始化时需要服从什么分布？\n",
    "- 参数调节搭配有什么技巧？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "# 初始化各层神经元节点个数\n",
    "hidden_nodes_1 = 1024\n",
    "hidden_nodes_2 = 512\n",
    "hidden_nodes_3 = 256\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # 输入数据\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "    tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    # 变量\n",
    "    # note：这里考到了神经网络中练习参数（权重和偏置项）个数的计算\n",
    "    # see：https://classroom.udacity.com/courses/ud730/lessons/6379031992/concepts/63789029420923\n",
    "    # 输入层→隐藏层：权重个数1024*1*1*(28*28)，偏置项个数1024\n",
    "    # 隐藏层→输出层：权重个数10*1*1*1024，偏置项个数10\n",
    "    # 输出层：10*1\n",
    "    # 构建n层神经元模型，首先分别初始化n组权重和偏置项系数\n",
    "    weights = [tf.Variable(tf.truncated_normal([image_size * image_size, hidden_nodes_1], stddev=np.sqrt(2.0/(image_size*image_size)))),\n",
    "               tf.Variable(tf.truncated_normal([hidden_nodes_1, hidden_nodes_2], stddev=np.sqrt(2.0/hidden_nodes_1))),\n",
    "               tf.Variable(tf.truncated_normal([hidden_nodes_2, hidden_nodes_3], stddev=np.sqrt(2.0/hidden_nodes_2))),\n",
    "               tf.Variable(tf.truncated_normal([hidden_nodes_3, num_labels], stddev=np.sqrt(2.0/hidden_nodes_3)))]\n",
    "    biases = [tf.Variable(tf.zeros([hidden_nodes_1])),\n",
    "              tf.Variable(tf.zeros([hidden_nodes_2])),\n",
    "              tf.Variable(tf.zeros([hidden_nodes_3])),\n",
    "              tf.Variable(tf.zeros([num_labels]))]\n",
    "    beta = 0.001\n",
    "    # 训练计算\n",
    "    # tf.nn.dropout(x, keep_prob,...)，keep_prob参数等于神经元参数保留的比例\n",
    "    # 第一层\n",
    "    keep_prob = tf.placeholder(\"float\")\n",
    "    hidden_layer_1 = tf.nn.relu(tf.add(tf.matmul(tf_train_dataset, weights[0]), biases[0]))\n",
    "    hidden_layer_1 = tf.nn.dropout(hidden_layer_1, keep_prob)\n",
    "    \n",
    "    # 第二层\n",
    "    hidden_layer_2 = tf.nn.relu(tf.add(tf.matmul(hidden_layer_1, weights[1]), biases[1]))\n",
    "    hidden_layer_2 = tf.nn.dropout(hidden_layer_2, keep_prob)\n",
    "    \n",
    "    # 第三层\n",
    "    hidden_layer_3 = tf.nn.relu(tf.add(tf.matmul(hidden_layer_2, weights[2]), biases[2]))\n",
    "    hidden_layer_3 = tf.nn.dropout(hidden_layer_3, keep_prob)\n",
    "    \n",
    "    # 输出层\n",
    "    logits = tf.matmul(hidden_layer_3, weights[3]) + biases[3] \n",
    "    \n",
    "    # 正则化\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=tf_train_labels))\n",
    "    regularization_0 = tf.nn.l2_loss(weights[0])\n",
    "    regularization_1 = tf.nn.l2_loss(weights[1])\n",
    "    regularization_2 = tf.nn.l2_loss(weights[2])\n",
    "    regularization_3 = tf.nn.l2_loss(weights[3])\n",
    "    regularization = regularization_0 + regularization_1 + regularization_2 + regularization_3\n",
    "    loss = tf.reduce_mean(loss + beta * regularization)\n",
    "    \n",
    "    # Optimizer.\n",
    "    # 学习率指数衰减\n",
    "    # decayed_learning_rate = learning_rate * decay_rate ^ (global_step / decay_steps)\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    start_learning_rate = 0.5\n",
    "    learning_rate = tf.train.exponential_decay(start_learning_rate, global_step, 100000, 0.96, staircase=True)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "    \n",
    "    # Predictions for the training\n",
    "    train_prediction = tf.nn.softmax(logits)\n",
    "    # Predictions for the validation\n",
    "    valid_logits_0 = tf.matmul(tf_valid_dataset, weights[0]) + biases[0]\n",
    "    valid_relu_0 = tf.nn.relu(valid_logits_0)\n",
    "    \n",
    "    valid_logits_1 = tf.matmul(valid_relu_0, weights[1]) + biases[1]\n",
    "    valid_relu_1 = tf.nn.relu(valid_logits_1)\n",
    "    \n",
    "    valid_logits_2 = tf.matmul(valid_relu_1, weights[2]) + biases[2]\n",
    "    valid_relu_2 = tf.nn.relu(valid_logits_2)\n",
    "    \n",
    "    valid_logits_3 = tf.matmul(valid_relu_2, weights[3]) + biases[3]\n",
    "    \n",
    "    valid_prediction = tf.nn.softmax(valid_logits_3)\n",
    "    # Predictions for the test\n",
    "    test_logits_0 = tf.matmul(tf_test_dataset, weights[0]) + biases[0]\n",
    "    test_relu_0 = tf.nn.relu(test_logits_0)\n",
    "    \n",
    "    test_logits_1 = tf.matmul(test_relu_0, weights[1]) + biases[1]\n",
    "    test_relu_1 = tf.nn.relu(test_logits_1)\n",
    "    \n",
    "    test_logits_2 = tf.matmul(test_relu_1, weights[2]) + biases[2]\n",
    "    test_relu_2 = tf.nn.relu(test_logits_2)\n",
    "    \n",
    "    test_logits_3 = tf.matmul(test_relu_2, weights[3]) + biases[3]\n",
    "    \n",
    "    test_prediction = tf.nn.softmax(test_logits_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-c6f3bf29a15c>:4: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized\n",
      "Minibatch loss at step 0: 4.163244247436523\n",
      "Minibatch accuracy: 10.2\n",
      "Validation accuracy: 27.9\n",
      "Minibatch loss at step 1000: 1.1067922115325928\n",
      "Minibatch accuracy: 88.3\n",
      "Validation accuracy: 85.0\n",
      "Minibatch loss at step 2000: 0.6307747960090637\n",
      "Minibatch accuracy: 94.5\n",
      "Validation accuracy: 86.4\n",
      "Minibatch loss at step 3000: 0.7727817296981812\n",
      "Minibatch accuracy: 86.7\n",
      "Validation accuracy: 87.4\n",
      "Minibatch loss at step 4000: 0.566569983959198\n",
      "Minibatch accuracy: 89.1\n",
      "Validation accuracy: 87.8\n",
      "Minibatch loss at step 5000: 0.6056175231933594\n",
      "Minibatch accuracy: 88.3\n",
      "Validation accuracy: 88.3\n",
      "Minibatch loss at step 6000: 0.5760238170623779\n",
      "Minibatch accuracy: 86.7\n",
      "Validation accuracy: 88.8\n",
      "Minibatch loss at step 7000: 0.4795209467411041\n",
      "Minibatch accuracy: 90.6\n",
      "Validation accuracy: 89.2\n",
      "Minibatch loss at step 8000: 0.4941803812980652\n",
      "Minibatch accuracy: 90.6\n",
      "Validation accuracy: 89.2\n",
      "Minibatch loss at step 9000: 0.3409796953201294\n",
      "Minibatch accuracy: 95.3\n",
      "Validation accuracy: 89.4\n",
      "Minibatch loss at step 10000: 0.6095467209815979\n",
      "Minibatch accuracy: 85.9\n",
      "Validation accuracy: 89.5\n",
      "Minibatch loss at step 11000: 0.4408193528652191\n",
      "Minibatch accuracy: 92.2\n",
      "Validation accuracy: 89.6\n",
      "Minibatch loss at step 12000: 0.5286339521408081\n",
      "Minibatch accuracy: 89.1\n",
      "Validation accuracy: 89.6\n",
      "测试集准确率: 95.2\n"
     ]
    }
   ],
   "source": [
    "num_steps = 12001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels, keep_prob : 0.5}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 1000== 0):\n",
    "            print(\"Minibatch loss at step {}: {}\".format(step, l))\n",
    "            print(\"Minibatch accuracy: {:.1f}\".format(accuracy(predictions, batch_labels)))\n",
    "            print(\"Validation accuracy: {:.1f}\".format(accuracy(valid_prediction.eval(), valid_labels)))\n",
    "    print(\"测试集准确率: {:.1f}\".format(accuracy(test_prediction.eval(), test_labels)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {
   "environment": null,
   "url": "https://anaconda.org/libin_ml/deep_learning_assignment_2"
  },
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
